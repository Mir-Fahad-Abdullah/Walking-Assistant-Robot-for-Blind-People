{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29bedd27-9dfa-4a39-854b-59824ffc4cd8",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba4e4041-d1ae-49d5-8e80-dfaaa56c76f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fahad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\fahad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "C:\\Users\\fahad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from absl import logging\n",
    "import shutil\n",
    "\n",
    "from tflite_model_maker import object_detector\n",
    "from tflite_model_maker.object_detector import DataLoader\n",
    "from tflite_model_maker.config import ExportFormat\n",
    "from tflite_model_maker import model_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb510ff-7e6d-40f1-89d1-89a206c26485",
   "metadata": {},
   "source": [
    "# Setting Up for TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd7889e-60d8-4c83-8711-5686af463fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "# Suppress TensorFlow and absl logs for cleaner output\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "logging.set_verbosity(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dbdad7-25d8-45c3-a473-a2eb62c17923",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing and Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e82dd74-fea9-4168-986a-346e7bc4b40a",
   "metadata": {},
   "source": [
    "### Directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5065e7de-fab6-46ac-a217-6eb091b2a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r'Object-detection-dataset'\n",
    "train_dir = 'Object-detection-dataset/train'\n",
    "valid_dir = 'Object-detection-dataset/valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f1b43b-864b-4057-b7e0-52f59a24f4bb",
   "metadata": {},
   "source": [
    "### Extracting Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d481960b-0242-4fb6-8b10-7fd2215a49d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels used in your annotations:\n",
      "Tom Tom\n",
      "aeroplane\n",
      "apple\n",
      "backpack\n",
      "banana\n",
      "baseball bat\n",
      "baseball glove\n",
      "bear\n",
      "bed\n",
      "bench\n",
      "bicycle\n",
      "bin\n",
      "bird\n",
      "boat\n",
      "book\n",
      "bottle\n",
      "bowl\n",
      "broccoli\n",
      "bus\n",
      "cake\n",
      "car\n",
      "cat\n",
      "cell phone\n",
      "chair\n",
      "clock\n",
      "cng\n",
      "cow\n",
      "cup\n",
      "diningtable\n",
      "dog\n",
      "donut\n",
      "door\n",
      "elephant\n",
      "fire hydrant\n",
      "fork\n",
      "frisbee\n",
      "giraffe\n",
      "glass partition\n",
      "handbag\n",
      "horse\n",
      "hot dog\n",
      "keyboard\n",
      "kite\n",
      "knife\n",
      "laptop\n",
      "microwave\n",
      "motorbike\n",
      "motorcycle\n",
      "mouse\n",
      "orange\n",
      "oven\n",
      "parking meter\n",
      "person\n",
      "pillar\n",
      "pizza\n",
      "pottedplant\n",
      "railing\n",
      "refrigerator\n",
      "remote\n",
      "rickshaw\n",
      "sandwich\n",
      "scissors\n",
      "sheep\n",
      "shelf\n",
      "sink\n",
      "skateboard\n",
      "skis\n",
      "snowboard\n",
      "sofa\n",
      "spoon\n",
      "sports ball\n",
      "stair\n",
      "stop sign\n",
      "suitcase\n",
      "surfboard\n",
      "table\n",
      "teddy bear\n",
      "tempu\n",
      "tennis racket\n",
      "tie\n",
      "toilet\n",
      "traffic light\n",
      "train\n",
      "tree\n",
      "truck\n",
      "tvmonitor\n",
      "umbrella\n",
      "van\n",
      "vase\n",
      "wine glass\n",
      "zebra\n"
     ]
    }
   ],
   "source": [
    "# Extract labels from XML files\n",
    "def extract_labels(directory):\n",
    "    labels = set()\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            tree = ET.parse(os.path.join(directory, filename))\n",
    "            root = tree.getroot()\n",
    "            for obj in root.findall('object'):\n",
    "                labels.add(obj.find('name').text)\n",
    "    return labels\n",
    "\n",
    "# Extract and merge all labels\n",
    "train_labels = extract_labels(train_dir)\n",
    "valid_labels = extract_labels(valid_dir)\n",
    "all_labels = sorted(train_labels.union(valid_labels))\n",
    "\n",
    "# Convert to the required label_map\n",
    "label_map = {i + 1: name for i, name in enumerate(all_labels)}\n",
    "\n",
    "# Display the labels\n",
    "print(\"Labels used in your annotations:\")\n",
    "for label in all_labels:\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d326b9d-5ed2-4fae-b820-3bb11a5a322d",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bec82316-9d6b-4b3b-8d73-bde8a63d2ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image, bbox):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_contrast(image, 0.9, 1.1)\n",
    "    return image, bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d7e270-68de-44d3-bbc4-539650a930a0",
   "metadata": {},
   "source": [
    "### Apply and Save Augmented Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "292327e4-7e85-43bd-95af-44099ec9ee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_dir = os.path.join(base_dir, 'train_augmented')\n",
    "os.makedirs(aug_dir, exist_ok=True)\n",
    "\n",
    "for file in os.listdir(train_dir):\n",
    "    if file.endswith('.jpg') or file.endswith('.png'):\n",
    "        base_name = os.path.splitext(file)[0]\n",
    "        img_path = os.path.join(train_dir, file)\n",
    "        xml_path = os.path.join(train_dir, base_name + '.xml')\n",
    "\n",
    "        if not os.path.exists(xml_path):\n",
    "            continue  # Skip if annotation missing\n",
    "\n",
    "        # Load and augment image\n",
    "        image = tf.io.read_file(img_path)\n",
    "        image = tf.image.decode_jpeg(image, channels = 3)\n",
    "        image = tf.image.resize(image, (256, 256))\n",
    "        image = tf.cast(image, tf.uint8)\n",
    "\n",
    "        aug_image, _ = augment_image(image, None)\n",
    "        aug_image = tf.image.encode_jpeg(tf.cast(aug_image, tf.uint8))\n",
    "\n",
    "        # Save augmented image\n",
    "        aug_img_name = base_name + '_aug.jpg'\n",
    "        aug_img_path = os.path.join(aug_dir, aug_img_name)\n",
    "        tf.io.write_file(aug_img_path, aug_image)\n",
    "\n",
    "        # Copy original XML with new name\n",
    "        aug_xml_name = base_name + '_aug.xml'\n",
    "        shutil.copy(xml_path, os.path.join(aug_dir, aug_xml_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8edf0e-f0a5-4f1a-8e8b-1aaaca06f247",
   "metadata": {},
   "source": [
    "### Merge Original and Augmented Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "130217f0-9175-49d7-a2ab-0b8959583179",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined_dir = os.path.join(base_dir, 'train_combined')\n",
    "os.makedirs(train_combined_dir, exist_ok = True)\n",
    "\n",
    "for src_dir in [train_dir, aug_dir]:\n",
    "    for f in os.listdir(src_dir):\n",
    "        shutil.copy(os.path.join(src_dir, f), os.path.join(train_combined_dir, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea82bd82-0bd9-479f-9556-246ec4e20b7c",
   "metadata": {},
   "source": [
    "### Load Dataset with Augmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43a89321-a041-4289-a5f5-c3bfb23a2524",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = object_detector.DataLoader.from_pascal_voc(\n",
    "    train_combined_dir,\n",
    "    train_combined_dir,\n",
    "    label_map\n",
    ")\n",
    "\n",
    "val_data = object_detector.DataLoader.from_pascal_voc(\n",
    "    valid_dir,\n",
    "    valid_dir,\n",
    "    label_map\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b34d95a-18f8-4dc7-98a0-5e5af039f0e2",
   "metadata": {},
   "source": [
    "# Initialize EfficientDet-Lite1 Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fc54268-8f22-47f6-b126-3353da5a5b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = model_spec.get(\"efficientdet_lite1\")\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "spec.optimizer = Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031c2a89-746c-4411-be71-5e6177524922",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab51d12-d9d2-4685-b781-5ee81d464a31",
   "metadata": {},
   "source": [
    "### Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a82a399a-84c1-42bd-9e9d-41e1e602adf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (256, 256)\n",
    "BATCH_SIZE = 8\n",
    "EPOCH_SIZE = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e26444a-5265-42b3-9343-2bb45e286325",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13c3fae1-b58e-41ce-9e7d-027d11b9352e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mobject_detector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_whole_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Freeze backbone, train only detection head\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_examples\\lite\\model_maker\\core\\task\\object_detector.py:260\u001b[0m, in \u001b[0;36mObjectDetector.create\u001b[1;34m(cls, train_data, model_spec, validation_data, epochs, batch_size, train_whole_model, do_train)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_train:\n\u001b[0;32m    259\u001b[0m   tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetraining the models...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 260\u001b[0m   \u001b[43mobject_detector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    262\u001b[0m   object_detector\u001b[38;5;241m.\u001b[39mcreate_model()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_examples\\lite\\model_maker\\core\\task\\object_detector.py:118\u001b[0m, in \u001b[0;36mObjectDetector.train\u001b[1;34m(self, train_data, validation_data, epochs, batch_size)\u001b[0m\n\u001b[0;32m    115\u001b[0m   validation_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_spec\u001b[38;5;241m.\u001b[39mds_strategy\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m--> 118\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m   train_ds, steps_per_epoch, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_dataset_and_steps(\n\u001b[0;32m    120\u001b[0m       train_data, batch_size, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    121\u001b[0m   validation_ds, validation_steps, val_json_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_dataset_and_steps(\n\u001b[0;32m    122\u001b[0m       validation_data, batch_size, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_examples\\lite\\model_maker\\core\\task\\object_detector.py:74\u001b[0m, in \u001b[0;36mObjectDetector.create_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_model\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel:\n\u001b[1;32m---> 74\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_examples\\lite\\model_maker\\core\\task\\model_spec\\object_detector_spec.py:238\u001b[0m, in \u001b[0;36mEfficientDetModelSpec.create_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_model\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel:\n\u001b[0;32m    237\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates the EfficientDet model.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrain_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEfficientDetNetTrainHub\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m      \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhub_module_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_examples\\lite\\model_maker\\third_party\\efficientdet\\keras\\train_lib.py:862\u001b[0m, in \u001b[0;36mEfficientDetNetTrainHub.__init__\u001b[1;34m(self, config, hub_module_url, name)\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhub_module_url \u001b[38;5;241m=\u001b[39m hub_module_url\n\u001b[1;32m--> 862\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model \u001b[38;5;241m=\u001b[39m \u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKerasLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhub_module_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;66;03m# class/box output prediction network.\u001b[39;00m\n\u001b[0;32m    865\u001b[0m num_anchors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(config\u001b[38;5;241m.\u001b[39maspect_ratios) \u001b[38;5;241m*\u001b[39m config\u001b[38;5;241m.\u001b[39mnum_scales\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:153\u001b[0m, in \u001b[0;36mKerasLayer.__init__\u001b[1;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape \u001b[38;5;241m=\u001b[39m data_structures\u001b[38;5;241m.\u001b[39mNoDependency(\n\u001b[0;32m    150\u001b[0m       _convert_nest_to_shapes(output_shape))\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_options \u001b[38;5;241m=\u001b[39m load_options\n\u001b[1;32m--> 153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func \u001b[38;5;241m=\u001b[39m \u001b[43mload_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_training_argument \u001b[38;5;241m=\u001b[39m func_has_training_argument(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func)\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_hub_module_v1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_hub_module_v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:449\u001b[0m, in \u001b[0;36mload_module\u001b[1;34m(handle, tags, load_options)\u001b[0m\n\u001b[0;32m    447\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:  \u001b[38;5;66;03m# Expected before TF2.4.\u001b[39;00m\n\u001b[0;32m    448\u001b[0m     set_load_options \u001b[38;5;241m=\u001b[39m load_options\n\u001b[1;32m--> 449\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodule_v2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mset_load_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_hub\\module_v2.py:106\u001b[0m, in \u001b[0;36mload\u001b[1;34m(handle, tags, options)\u001b[0m\n\u001b[0;32m    103\u001b[0m   obj \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39msaved_model\u001b[38;5;241m.\u001b[39mload_v2(\n\u001b[0;32m    104\u001b[0m       module_path, tags\u001b[38;5;241m=\u001b[39mtags, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 106\u001b[0m   obj \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m obj\u001b[38;5;241m.\u001b[39m_is_hub_module_v1 \u001b[38;5;241m=\u001b[39m is_hub_module_v1  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:936\u001b[0m, in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_model.load\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_model.load_v2\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(export_dir, tags\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    847\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Load a SavedModel from `export_dir`.\u001b[39;00m\n\u001b[0;32m    848\u001b[0m \n\u001b[0;32m    849\u001b[0m \u001b[38;5;124;03m  Signatures associated with the SavedModel are available as functions:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;124;03m    ValueError: If `tags` don't match a MetaGraph in the SavedModel.\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 936\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mload_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    937\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:974\u001b[0m, in \u001b[0;36mload_internal\u001b[1;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minit_scope():\n\u001b[0;32m    973\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 974\u001b[0m     loader \u001b[38;5;241m=\u001b[39m \u001b[43mloader_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobject_graph_proto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved_model_proto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mckpt_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    976\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    978\u001b[0m         \u001b[38;5;28mstr\u001b[39m(err) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m You may be trying to load on a different device \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    979\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom the computational device. Consider setting the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    980\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    981\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto the io_device such as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/job:localhost\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:149\u001b[0m, in \u001b[0;36mLoader.__init__\u001b[1;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proto \u001b[38;5;241m=\u001b[39m object_graph_proto\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export_dir \u001b[38;5;241m=\u001b[39m export_dir\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_functions \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 149\u001b[0m     \u001b[43mfunction_deserialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_function_def_library\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43msaved_object_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_proto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrapper_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_WrapperFunction\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Store a set of all concrete functions that have been set up with\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# captures.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restored_concrete_functions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:412\u001b[0m, in \u001b[0;36mload_function_def_library\u001b[1;34m(library, saved_object_graph, load_shared_name_suffix, wrapper_function)\u001b[0m\n\u001b[0;32m    406\u001b[0m   func_graph \u001b[38;5;241m=\u001b[39m function_def_lib\u001b[38;5;241m.\u001b[39mfunction_def_to_graph(\n\u001b[0;32m    407\u001b[0m       copy,\n\u001b[0;32m    408\u001b[0m       structured_input_signature\u001b[38;5;241m=\u001b[39mstructured_input_signature,\n\u001b[0;32m    409\u001b[0m       structured_outputs\u001b[38;5;241m=\u001b[39mstructured_outputs)\n\u001b[0;32m    410\u001b[0m \u001b[38;5;66;03m# Restores gradients for function-call ops (not the same as ops that use\u001b[39;00m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;66;03m# custom gradients)\u001b[39;00m\n\u001b[1;32m--> 412\u001b[0m \u001b[43m_restore_gradient_functions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenamed_functions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaded_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dep \u001b[38;5;129;01min\u001b[39;00m function_deps[fdef\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname]:\n\u001b[0;32m    415\u001b[0m   functions[dep]\u001b[38;5;241m.\u001b[39madd_to_graph(func_graph)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:476\u001b[0m, in \u001b[0;36m_restore_gradient_functions\u001b[1;34m(func_graph, renamed_functions, loaded_gradients)\u001b[0m\n\u001b[0;32m    474\u001b[0m   op\u001b[38;5;241m.\u001b[39m_gradient_function \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39m_get_gradient_function()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 476\u001b[0m   gradient_op_type \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_attr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_gradient_op_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2690\u001b[0m, in \u001b[0;36mOperation.get_attr\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m c_api_util\u001b[38;5;241m.\u001b[39mtf_buffer() \u001b[38;5;28;01mas\u001b[39;00m buf:\n\u001b[1;32m-> 2690\u001b[0m     \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_OperationGetAttrValueProto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2691\u001b[0m     data \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(buf)\n\u001b[0;32m   2692\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2693\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py:275\u001b[0m, in \u001b[0;36mInvalidArgumentError.__init__\u001b[1;34m(self, node_def, op, message, *args)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, node_def, op, message, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m    274\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates an `InvalidArgumentError`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 275\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m(InvalidArgumentError, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(node_def, op, message,\n\u001b[0;32m    276\u001b[0m                                              INVALID_ARGUMENT, \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = object_detector.create(\n",
    "    train_data,\n",
    "    model_spec=spec,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    train_whole_model=False,  # Freeze backbone, train only detection head\n",
    "    validation_data=val_data,\n",
    "    epochs=EPOCH_SIZE,\n",
    "    do_train=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f106caa8-565a-437d-9a41-86a9f237cd74",
   "metadata": {},
   "source": [
    "# Model Summary and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a23383c-fd7c-4183-b0ae-17211355ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.summary()\n",
    "plot_model(model.model, show_shapes=True, show_layer_names=True, dpi=96, to_file=\"model_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5777edb4-c94f-48ba-abf6-9c703ca7f569",
   "metadata": {},
   "source": [
    "# Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad99f91-44bd-43d0-b22d-64039847729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.model.history\n",
    "\n",
    "if history and hasattr(history, 'history'):\n",
    "    plt.figure(figsize = (10, 5))\n",
    "    for key, values in history.history.items():\n",
    "        plt.plot(values, label=key)\n",
    "    plt.title('Learning Curves')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Metric')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4ce60d-d499-4ccb-a4fa-8b32ff1424b6",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1853c3b-6b86-481a-94d3-31125b3583d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.evaluate(val_data)\n",
    "\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f792b1-4c03-41c6-8645-21d5e315c7f5",
   "metadata": {},
   "source": [
    "# Export TFLite (float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58b7300-7ca9-4035-bbbe-8a88ab3fb79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflite_model_maker.config import QuantizationConfig\n",
    "\n",
    "model.export(\n",
    "    export_dir='.',\n",
    "    export_format=[ExportFormat.TFLITE],\n",
    "    quantization_config=QuantizationConfig.for_float16()\n",
    ")\n",
    "\n",
    "os.rename(\"model.tflite\", \"EfficientDet_Lite1_detector_float16.tflite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
