{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5492e5f-5806-4d6c-9335-5bd3e31933e3",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74911a1d-f2dc-4bcd-9bd5-f34b2198ffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import re\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import cv2\n",
    "\n",
    "from absl import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edccc8b4-6fd6-4221-ac44-85df02d389e8",
   "metadata": {},
   "source": [
    "# Setting Up for TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b10ec45-88d2-474f-9d6c-473701e21dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "# Suppress TensorFlow and absl logs for cleaner output\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "logging.set_verbosity(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be1031a-3786-40f0-ab7f-624611d6980e",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing and Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbb6834-6519-401b-8193-462980c3d189",
   "metadata": {},
   "source": [
    "### Directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6197e659-2094-4554-a0d6-2c72e1bd3767",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r'Object-detection-dataset'\n",
    "train_dir = 'Object-detection-dataset/train'\n",
    "valid_dir = 'Object-detection-dataset/valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a1c6ad-ad4c-4385-a3ca-b5796eb1f987",
   "metadata": {},
   "source": [
    "### Extracting Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48480c57-e5d2-431f-9acd-e50795c869a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels used in your annotations:\n",
      "aeroplane\n",
      "apple\n",
      "backpack\n",
      "banana\n",
      "baseball bat\n",
      "baseball glove\n",
      "bear\n",
      "bed\n",
      "bench\n",
      "bicycle\n",
      "bird\n",
      "boat\n",
      "book\n",
      "bottle\n",
      "bowl\n",
      "broccoli\n",
      "bus\n",
      "cake\n",
      "car\n",
      "carrot\n",
      "cat\n",
      "cell phone\n",
      "chair\n",
      "clock\n",
      "cow\n",
      "cup\n",
      "diningtable\n",
      "dog\n",
      "donut\n",
      "elephant\n",
      "fire hydrant\n",
      "fork\n",
      "frisbee\n",
      "giraffe\n",
      "hair drier\n",
      "handbag\n",
      "horse\n",
      "hot dog\n",
      "keyboard\n",
      "kite\n",
      "knife\n",
      "laptop\n",
      "microwave\n",
      "motorbike\n",
      "mouse\n",
      "orange\n",
      "oven\n",
      "parking meter\n",
      "person\n",
      "pizza\n",
      "pottedplant\n",
      "refrigerator\n",
      "remote\n",
      "sandwich\n",
      "scissors\n",
      "sheep\n",
      "sink\n",
      "skateboard\n",
      "skis\n",
      "snowboard\n",
      "sofa\n",
      "spoon\n",
      "sports ball\n",
      "stop sign\n",
      "suitcase\n",
      "surfboard\n",
      "teddy bear\n",
      "tennis racket\n",
      "tie\n",
      "toaster\n",
      "toilet\n",
      "toothbrush\n",
      "traffic light\n",
      "train\n",
      "truck\n",
      "tvmonitor\n",
      "umbrella\n",
      "vase\n",
      "wine glass\n",
      "zebra\n"
     ]
    }
   ],
   "source": [
    "# Extract labels from XML files\n",
    "def extract_labels(directory):\n",
    "    labels = set()\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            tree = ET.parse(os.path.join(directory, filename))\n",
    "            root = tree.getroot()\n",
    "            for obj in root.findall('object'):\n",
    "                labels.add(obj.find('name').text)\n",
    "    return labels\n",
    "\n",
    "# Extract and merge all labels\n",
    "train_labels = extract_labels(train_dir)\n",
    "valid_labels = extract_labels(valid_dir)\n",
    "all_labels = sorted(train_labels.union(valid_labels))\n",
    "\n",
    "# Convert to the required label_map\n",
    "label_map = {i + 1: name for i, name in enumerate(all_labels)}\n",
    "\n",
    "# Display the labels\n",
    "print(\"Labels used in your annotations:\")\n",
    "for label in all_labels:\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c0adcc-52a9-49c6-8444-ebb10a133bcc",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1de03188-2c2e-4391-ae40-54675fe34bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image, bbox):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_contrast(image, 0.9, 1.1)\n",
    "    return image, bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9eae6b-8027-4058-9a7a-84da48e67f6b",
   "metadata": {},
   "source": [
    "### Apply and Save Augmented Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "013b16de-b42a-4214-8065-30358b59d931",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_dir = os.path.join(base_dir, 'train_augmented')\n",
    "os.makedirs(aug_dir, exist_ok=True)\n",
    "\n",
    "for file in os.listdir(train_dir):\n",
    "    if file.endswith('.jpg') or file.endswith('.png'):\n",
    "        base_name = os.path.splitext(file)[0]\n",
    "        img_path = os.path.join(train_dir, file)\n",
    "        xml_path = os.path.join(train_dir, base_name + '.xml')\n",
    "\n",
    "        if not os.path.exists(xml_path):\n",
    "            continue  # Skip if annotation missing\n",
    "\n",
    "        # Load and augment image\n",
    "        image = tf.io.read_file(img_path)\n",
    "        image = tf.image.decode_jpeg(image, channels = 3)\n",
    "        image = tf.image.resize(image, (320, 320))\n",
    "        image = tf.cast(image, tf.uint8)\n",
    "\n",
    "        aug_image, _ = augment_image(image, None)\n",
    "        aug_image = tf.image.encode_jpeg(tf.cast(aug_image, tf.uint8))\n",
    "\n",
    "        # Save augmented image\n",
    "        aug_img_name = base_name + '_aug.jpg'\n",
    "        aug_img_path = os.path.join(aug_dir, aug_img_name)\n",
    "        tf.io.write_file(aug_img_path, aug_image)\n",
    "\n",
    "        # Copy original XML with new name\n",
    "        aug_xml_name = base_name + '_aug.xml'\n",
    "        shutil.copy(xml_path, os.path.join(aug_dir, aug_xml_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba343c0-5136-4d85-b6e7-d30c25508678",
   "metadata": {},
   "source": [
    "### Combine original and augmented training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1449e597-4a3a-4b59-ab3e-03329d893981",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined_dir = os.path.join(base_dir, 'train_combined')\n",
    "os.makedirs(train_combined_dir, exist_ok = True)\n",
    "\n",
    "for src_dir in [train_dir, aug_dir]:\n",
    "    for f in os.listdir(src_dir):\n",
    "        shutil.copy(os.path.join(src_dir, f), os.path.join(train_combined_dir, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e23299-c96e-4d90-982a-3779bedbff10",
   "metadata": {},
   "source": [
    "### Generate train.txt and val.txt file lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b02ac663-3bed-46e5-b472-537db7da51cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list_path = 'annotations/train.txt'\n",
    "val_list_path = 'annotations/val.txt'\n",
    "\n",
    "# Generate train.txt from combined directory\n",
    "train_files = [os.path.splitext(f)[0] for f in os.listdir(train_combined_dir) if f.endswith('.xml')]\n",
    "with open(train_list_path, 'w') as f:\n",
    "    for name in sorted(set(train_files)):\n",
    "        f.write(f\"{name}\")\n",
    "\n",
    "# Generate val.txt from validation directory\n",
    "val_files = [os.path.splitext(f)[0] for f in os.listdir(valid_dir) if f.endswith('.xml')]\n",
    "with open(val_list_path, 'w') as f:\n",
    "    for name in sorted(set(val_files)):\n",
    "        f.write(f\"{name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056b7cfd-232e-45d0-8281-3134aa8130a9",
   "metadata": {},
   "source": [
    "### Convert XML annotations to TFRecord files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eeb27242-3a0a-4f74-b90f-9e5aeba4e8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 23:02:01.860115: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2025-06-12 23:02:01.860166: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\fahad\\Music\\models\\research\\object_detection\\dataset_tools\\create_pascal_tf_record.py\", line 37, in <module>\n",
      "    from object_detection.utils import dataset_util\n",
      "ModuleNotFoundError: No module named 'object_detection'\n",
      "2025-06-12 23:02:06.943899: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2025-06-12 23:02:06.943934: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\fahad\\Music\\models\\research\\object_detection\\dataset_tools\\create_pascal_tf_record.py\", line 37, in <module>\n",
      "    from object_detection.utils import dataset_util\n",
      "ModuleNotFoundError: No module named 'object_detection'\n"
     ]
    }
   ],
   "source": [
    "!python models/research/object_detection/dataset_tools/create_pascal_tf_record.py \\\n",
    "  --label_map_path=annotations/label_map.pbtxt \\\n",
    "  --data_dir=Object-detection-dataset \\\n",
    "  --output_path=annotations/train.record \\\n",
    "  --examples_path=annotations/train.txt\n",
    "\n",
    "!python models/research/object_detection/dataset_tools/create_pascal_tf_record.py \\\n",
    "  --label_map_path=annotations/label_map.pbtxt \\\n",
    "  --data_dir=Object-detection-dataset \\\n",
    "  --output_path=annotations/val.record \\\n",
    "  --examples_path=annotations/val.txt\n",
    "train_combined_dir = os.path.join(base_dir, 'train_combined')\n",
    "os.makedirs(train_combined_dir, exist_ok=True)\n",
    "\n",
    "for src_dir in [train_dir, aug_dir]:\n",
    "    for f in os.listdir(src_dir):\n",
    "        shutil.copy(os.path.join(src_dir, f), os.path.join(train_combined_dir, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09210811-8643-450a-8896-75e86637833d",
   "metadata": {},
   "source": [
    "# Install TF2 Detection API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c11b68f9-66ff-46fb-b4aa-01fa8ff30182",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "MODEL_DATE = '20200711'\n",
    "MODEL_BASE = f'http://download.tensorflow.org/models/object_detection/tf2/{MODEL_DATE}'\n",
    "MODEL_TAR = f'{MODEL_NAME}.tar.gz'\n",
    "\n",
    "urllib.request.urlretrieve(f'{MODEL_BASE}/{MODEL_TAR}', MODEL_TAR)\n",
    "with tarfile.open(MODEL_TAR) as tar:\n",
    "    tar.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d16e114-8bde-4b6a-bf56-005c47e22d84",
   "metadata": {},
   "source": [
    "# Write Label Map File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eefb7d76-1c2d-4608-b42e-8ed0776cd4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map_path = 'annotations/label_map.pbtxt'\n",
    "os.makedirs(os.path.dirname(label_map_path), exist_ok=True)\n",
    "\n",
    "with open(label_map_path, 'w') as f:\n",
    "    for id, name in label_map.items():\n",
    "        f.write(f\"item {{\\n  id: {id}\\n  name: '{name}'\\n}}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3264a3-364f-4b05-a535-00a0a70909d3",
   "metadata": {},
   "source": [
    "# Modify pipeline.config for Custom Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ef37ec9-ada6-437f-b892-14637d909cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_path = f'{MODEL_NAME}/pipeline.config'\n",
    "new_pipeline_path = f'{MODEL_NAME}/custom_pipeline.config'\n",
    "\n",
    "with open(pipeline_path, 'r') as f:\n",
    "    config = f.read()\n",
    "\n",
    "config = re.sub('fine_tune_checkpoint: \".*?\"', f'fine_tune_checkpoint: \"{MODEL_NAME}/checkpoint/ckpt-0\"', config)\n",
    "config = re.sub('label_map_path: \".*?\"', 'label_map_path: \"annotations/label_map.pbtxt\"', config)\n",
    "config = re.sub('input_path: \".*?train.*?\"', 'input_path: \"annotations/train.record\"', config)\n",
    "config = re.sub('input_path: \".*?val.*?\"', 'input_path: \"annotations/val.record\"', config)\n",
    "config = re.sub('num_classes: [0-9]+', f'num_classes: {len(label_map)}', config)\n",
    "config = re.sub('batch_size: [0-9]+', 'batch_size: 8', config)\n",
    "config = re.sub('num_steps: [0-9]+', 'num_steps: 1000', config)\n",
    "\n",
    "with open(new_pipeline_path, 'w') as f:\n",
    "    f.write(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e2a409-a540-45e4-830e-7df6ac67a020",
   "metadata": {},
   "source": [
    "# Training the Model Using TF2 Detection API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "842bc9cb-07c3-4364-b51e-3ea1a4daabfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 22:52:14.883321: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2025-06-12 22:52:14.883374: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\fahad\\Music\\models\\research\\object_detection\\model_main_tf2.py\", line 31, in <module>\n",
      "    from object_detection import model_lib_v2\n",
      "ModuleNotFoundError: No module named 'object_detection'\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.abspath(\"models\"))\n",
    "sys.path.append(os.path.abspath(\"models/research\"))\n",
    "\n",
    "!python models/research/object_detection/model_main_tf2.py \\\n",
    "    --pipeline_config_path=ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/custom_pipeline.config \\\n",
    "    --model_dir=training/ \\\n",
    "    --alsologtostderr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d177c18-489f-4d06-94f0-daa31a624d34",
   "metadata": {},
   "source": [
    "# Export Final SavedModel for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd6fd19-8bdb-480d-9e97-df5b7dbccaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python models/research/object_detection/exporter_main_v2.py \\\n",
    "    --input_type image_tensor \\\n",
    "    --pipeline_config_path=ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/custom_pipeline.config \\\n",
    "    --trained_checkpoint_dir=training/ \\\n",
    "    --output_directory=exported_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100583a9-07a2-443d-89ff-fa9ce027cd7b",
   "metadata": {},
   "source": [
    "# Load Exported Model and Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd303e0-3689-44cd-b317-01bdd5e7269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import label_map_util, visualization_utils as viz_utils\n",
    "\n",
    "detect_fn = tf.saved_model.load('exported_model/saved_model')\n",
    "category_index = label_map_util.create_category_index_from_labelmap('annotations/label_map.pbtxt')\n",
    "\n",
    "img_path = 'path/to/test/image.jpg'\n",
    "image_np = cv2.imread(img_path)\n",
    "input_tensor = tf.convert_to_tensor(image_np[None, ...])\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "    image_np,\n",
    "    detections['detection_boxes'][0].numpy(),\n",
    "    detections['detection_classes'][0].numpy().astype(np.int32),\n",
    "    detections['detection_scores'][0].numpy(),\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    max_boxes_to_draw=10,\n",
    "    min_score_thresh=0.5\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
