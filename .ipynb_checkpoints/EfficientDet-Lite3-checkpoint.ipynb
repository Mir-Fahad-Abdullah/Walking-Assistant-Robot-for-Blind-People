{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35c0aa73-0562-4c2b-9087-8e6ea1d2e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements-working.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bedd27-9dfa-4a39-854b-59824ffc4cd8",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba4e4041-d1ae-49d5-8e80-dfaaa56c76f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fahad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\fahad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "C:\\Users\\fahad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from absl import logging\n",
    "import shutil\n",
    "\n",
    "from tflite_model_maker import object_detector\n",
    "from tflite_model_maker.config import ExportFormat\n",
    "from tflite_model_maker import model_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb510ff-7e6d-40f1-89d1-89a206c26485",
   "metadata": {},
   "source": [
    "# Setting Up for TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cd7889e-60d8-4c83-8711-5686af463fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "# Suppress TensorFlow and absl logs for cleaner output\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "logging.set_verbosity(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e82dd74-fea9-4168-986a-346e7bc4b40a",
   "metadata": {},
   "source": [
    "# Directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5065e7de-fab6-46ac-a217-6eb091b2a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r'Object-detection-dataset'\n",
    "train_dir = 'Object-detection-dataset/train'\n",
    "valid_dir = 'Object-detection-dataset/valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f1b43b-864b-4057-b7e0-52f59a24f4bb",
   "metadata": {},
   "source": [
    "# Extracting Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d481960b-0242-4fb6-8b10-7fd2215a49d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels used in your annotations:\n",
      "Tom Tom\n",
      "aeroplane\n",
      "apple\n",
      "backpack\n",
      "banana\n",
      "baseball bat\n",
      "baseball glove\n",
      "bear\n",
      "bed\n",
      "bench\n",
      "bicycle\n",
      "bin\n",
      "bird\n",
      "boat\n",
      "book\n",
      "bottle\n",
      "bowl\n",
      "broccoli\n",
      "bus\n",
      "cake\n",
      "car\n",
      "cat\n",
      "cell phone\n",
      "chair\n",
      "clock\n",
      "cng\n",
      "cow\n",
      "cup\n",
      "diningtable\n",
      "dog\n",
      "donut\n",
      "door\n",
      "elephant\n",
      "fire hydrant\n",
      "fork\n",
      "frisbee\n",
      "giraffe\n",
      "glass partition\n",
      "handbag\n",
      "horse\n",
      "hot dog\n",
      "keyboard\n",
      "kite\n",
      "knife\n",
      "laptop\n",
      "microwave\n",
      "motorbike\n",
      "motorcycle\n",
      "mouse\n",
      "orange\n",
      "oven\n",
      "parking meter\n",
      "person\n",
      "pillar\n",
      "pizza\n",
      "pottedplant\n",
      "railing\n",
      "refrigerator\n",
      "remote\n",
      "rickshaw\n",
      "sandwich\n",
      "scissors\n",
      "sheep\n",
      "shelf\n",
      "sink\n",
      "skateboard\n",
      "skis\n",
      "snowboard\n",
      "sofa\n",
      "spoon\n",
      "sports ball\n",
      "stair\n",
      "stop sign\n",
      "suitcase\n",
      "surfboard\n",
      "table\n",
      "teddy bear\n",
      "tempu\n",
      "tennis racket\n",
      "tie\n",
      "toilet\n",
      "traffic light\n",
      "train\n",
      "tree\n",
      "truck\n",
      "tvmonitor\n",
      "umbrella\n",
      "van\n",
      "vase\n",
      "wine glass\n",
      "zebra\n"
     ]
    }
   ],
   "source": [
    "# Extract labels from XML files\n",
    "def extract_labels(directory):\n",
    "    labels = set()\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            tree = ET.parse(os.path.join(directory, filename))\n",
    "            root = tree.getroot()\n",
    "            for obj in root.findall('object'):\n",
    "                labels.add(obj.find('name').text)\n",
    "    return labels\n",
    "\n",
    "# Extract and merge all labels\n",
    "train_labels = extract_labels(train_dir)\n",
    "valid_labels = extract_labels(valid_dir)\n",
    "all_labels = sorted(train_labels.union(valid_labels))\n",
    "\n",
    "# Convert to the required label_map\n",
    "label_map = {i + 1: name for i, name in enumerate(all_labels)}\n",
    "\n",
    "# Display the labels\n",
    "print(\"Labels used in your annotations:\")\n",
    "for label in all_labels:\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d326b9d-5ed2-4fae-b820-3bb11a5a322d",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bec82316-9d6b-4b3b-8d73-bde8a63d2ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image, bbox):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_contrast(image, 0.9, 1.1)\n",
    "    return image, bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d7e270-68de-44d3-bbc4-539650a930a0",
   "metadata": {},
   "source": [
    "# Apply and Save Augmented Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "292327e4-7e85-43bd-95af-44099ec9ee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_dir = os.path.join(base_dir, 'train_augmented')\n",
    "os.makedirs(aug_dir, exist_ok=True)\n",
    "\n",
    "for file in os.listdir(train_dir):\n",
    "    if file.endswith('.jpg') or file.endswith('.png'):\n",
    "        base_name = os.path.splitext(file)[0]\n",
    "        img_path = os.path.join(train_dir, file)\n",
    "        xml_path = os.path.join(train_dir, base_name + '.xml')\n",
    "\n",
    "        if not os.path.exists(xml_path):\n",
    "            continue  # Skip if annotation missing\n",
    "\n",
    "        # Load and augment image\n",
    "        image = tf.io.read_file(img_path)\n",
    "        image = tf.image.decode_jpeg(image, channels = 3)\n",
    "        image = tf.image.resize(image, (256, 256))\n",
    "        image = tf.cast(image, tf.uint8)\n",
    "\n",
    "        aug_image, _ = augment_image(image, None)\n",
    "        aug_image = tf.image.encode_jpeg(tf.cast(aug_image, tf.uint8))\n",
    "\n",
    "        # Save augmented image\n",
    "        aug_img_name = base_name + '_aug.jpg'\n",
    "        aug_img_path = os.path.join(aug_dir, aug_img_name)\n",
    "        tf.io.write_file(aug_img_path, aug_image)\n",
    "\n",
    "        # Copy original XML with new name\n",
    "        aug_xml_name = base_name + '_aug.xml'\n",
    "        shutil.copy(xml_path, os.path.join(aug_dir, aug_xml_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8edf0e-f0a5-4f1a-8e8b-1aaaca06f247",
   "metadata": {},
   "source": [
    "# Merge Original and Augmented Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "130217f0-9175-49d7-a2ab-0b8959583179",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined_dir = os.path.join(base_dir, 'train_combined')\n",
    "os.makedirs(train_combined_dir, exist_ok = True)\n",
    "\n",
    "for src_dir in [train_dir, aug_dir]:\n",
    "    for f in os.listdir(src_dir):\n",
    "        shutil.copy(os.path.join(src_dir, f), os.path.join(train_combined_dir, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea82bd82-0bd9-479f-9556-246ec4e20b7c",
   "metadata": {},
   "source": [
    "# Load Dataset with Augmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43a89321-a041-4289-a5f5-c3bfb23a2524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_data = object_detector.DataLoader.from_pascal_voc(\n",
    "    train_combined_dir,\n",
    "    train_combined_dir,\n",
    "    label_map\n",
    ")\n",
    "\n",
    "# Load validation data\n",
    "val_data = object_detector.DataLoader.from_pascal_voc(\n",
    "    valid_dir,\n",
    "    valid_dir,\n",
    "    label_map\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b34d95a-18f8-4dc7-98a0-5e5af039f0e2",
   "metadata": {},
   "source": [
    "# Initialize EfficientDet-Lite1 Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fc54268-8f22-47f6-b126-3353da5a5b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = model_spec.get(\"efficientdet_lite3\")\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "spec.optimizer = Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab51d12-d9d2-4685-b781-5ee81d464a31",
   "metadata": {},
   "source": [
    "# Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a82a399a-84c1-42bd-9e9d-41e1e602adf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (256, 256)\n",
    "BATCH_SIZE = 8\n",
    "EPOCH_SIZE = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e26444a-5265-42b3-9343-2bb45e286325",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13c3fae1-b58e-41ce-9e7d-027d11b9352e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "102/102 [==============================] - 1167s 11s/step - det_loss: 1.7542 - cls_loss: 1.2957 - box_loss: 0.0092 - reg_l2_loss: 0.0224 - loss: 1.7765 - learning_rate: 0.0090 - gradient_norm: 0.7381 - val_det_loss: 1.4574 - val_cls_loss: 1.1257 - val_box_loss: 0.0066 - val_reg_l2_loss: 0.0224 - val_loss: 1.4798\n",
      "Epoch 2/50\n",
      "102/102 [==============================] - 1085s 11s/step - det_loss: 1.3498 - cls_loss: 1.0597 - box_loss: 0.0058 - reg_l2_loss: 0.0224 - loss: 1.3722 - learning_rate: 0.0100 - gradient_norm: 0.9599 - val_det_loss: 1.3531 - val_cls_loss: 1.0487 - val_box_loss: 0.0061 - val_reg_l2_loss: 0.0224 - val_loss: 1.3756\n",
      "Epoch 3/50\n",
      "102/102 [==============================] - 808s 8s/step - det_loss: 1.1873 - cls_loss: 0.9319 - box_loss: 0.0051 - reg_l2_loss: 0.0224 - loss: 1.2097 - learning_rate: 0.0099 - gradient_norm: 0.9183 - val_det_loss: 1.1922 - val_cls_loss: 0.9119 - val_box_loss: 0.0056 - val_reg_l2_loss: 0.0224 - val_loss: 1.2146\n",
      "Epoch 4/50\n",
      "102/102 [==============================] - 779s 8s/step - det_loss: 1.0496 - cls_loss: 0.7977 - box_loss: 0.0050 - reg_l2_loss: 0.0225 - loss: 1.0721 - learning_rate: 0.0099 - gradient_norm: 1.0367 - val_det_loss: 1.0604 - val_cls_loss: 0.7848 - val_box_loss: 0.0055 - val_reg_l2_loss: 0.0225 - val_loss: 1.0829\n",
      "Epoch 5/50\n",
      "102/102 [==============================] - ETA: 0s - det_loss: 0.8911 - cls_loss: 0.6500 - box_loss: 0.0048 - reg_l2_loss: 0.0225 - loss: 0.9136 - learning_rate: 0.0098 - gradient_norm: 1.0652"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'info'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mobject_detector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_whole_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Freeze backbone, train only detection head\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_examples\\lite\\model_maker\\core\\task\\object_detector.py:260\u001b[0m, in \u001b[0;36mObjectDetector.create\u001b[1;34m(cls, train_data, model_spec, validation_data, epochs, batch_size, train_whole_model, do_train)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_train:\n\u001b[0;32m    259\u001b[0m   tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetraining the models...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 260\u001b[0m   \u001b[43mobject_detector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    262\u001b[0m   object_detector\u001b[38;5;241m.\u001b[39mcreate_model()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_examples\\lite\\model_maker\\core\\task\\object_detector.py:123\u001b[0m, in \u001b[0;36mObjectDetector.train\u001b[1;34m(self, train_data, validation_data, epochs, batch_size)\u001b[0m\n\u001b[0;32m    119\u001b[0m train_ds, steps_per_epoch, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_dataset_and_steps(\n\u001b[0;32m    120\u001b[0m     train_data, batch_size, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    121\u001b[0m validation_ds, validation_steps, val_json_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_dataset_and_steps(\n\u001b[0;32m    122\u001b[0m     validation_data, batch_size, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mvalidation_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_json_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_examples\\lite\\model_maker\\core\\task\\model_spec\\object_detector_spec.py:266\u001b[0m, in \u001b[0;36mEfficientDetModelSpec.train\u001b[1;34m(self, model, train_dataset, steps_per_epoch, val_dataset, validation_steps, epochs, batch_size, val_json_file)\u001b[0m\n\u001b[0;32m    264\u001b[0m train\u001b[38;5;241m.\u001b[39msetup_model(model, config)\n\u001b[0;32m    265\u001b[0m train\u001b[38;5;241m.\u001b[39minit_experimental(config)\n\u001b[1;32m--> 266\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_examples\\lite\\model_maker\\third_party\\efficientdet\\keras\\train_lib.py:358\u001b[0m, in \u001b[0;36mCOCOCallback.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (images, labels) \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[0;32m    357\u001b[0m   strategy\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_detections, (images, labels))\n\u001b[1;32m--> 358\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    359\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_writer\u001b[38;5;241m.\u001b[39mas_default(), tf\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39mrecord_if(\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_examples\\lite\\model_maker\\third_party\\efficientdet\\coco_metric.py:174\u001b[0m, in \u001b[0;36mEvaluationMetric.result\u001b[1;34m(self, log_level)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the metric values (and compute it if needed).\"\"\"\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_level\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_values\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_examples\\lite\\model_maker\\third_party\\efficientdet\\coco_metric.py:143\u001b[0m, in \u001b[0;36mEvaluationMetric.evaluate\u001b[1;34m(self, log_level)\u001b[0m\n\u001b[0;32m    141\u001b[0m detections \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetections)\n\u001b[0;32m    142\u001b[0m image_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(detections[:, \u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m--> 143\u001b[0m coco_dt \u001b[38;5;241m=\u001b[39m \u001b[43mcoco_gt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadRes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetections\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m coco_eval \u001b[38;5;241m=\u001b[39m COCOeval(coco_gt, coco_dt, iouType\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbbox\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    145\u001b[0m coco_eval\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mimgIds \u001b[38;5;241m=\u001b[39m image_ids\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pycocotools\\coco.py:314\u001b[0m, in \u001b[0;36mCOCO.loadRes\u001b[1;34m(self, resFile)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03mLoad result file and return a result api object.\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;124;03m:param   resFile (str)     : file name of result file\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;124;03m:return: res (obj)         : result api object\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    313\u001b[0m res \u001b[38;5;241m=\u001b[39m COCO()\n\u001b[1;32m--> 314\u001b[0m res\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minfo\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minfo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m    315\u001b[0m res\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [img \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading and preparing results...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'info'"
     ]
    }
   ],
   "source": [
    "model = object_detector.create(\n",
    "    train_data,\n",
    "    model_spec=spec,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    train_whole_model=False,  # Freeze backbone, train only detection head\n",
    "    validation_data=val_data,\n",
    "    epochs=EPOCH_SIZE,\n",
    "    do_train=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f106caa8-565a-437d-9a41-86a9f237cd74",
   "metadata": {},
   "source": [
    "# Model Summary and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a23383c-fd7c-4183-b0ae-17211355ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.summary()\n",
    "plot_model(model.model, show_shapes = True, show_layer_names = True, dpi = 96)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5777edb4-c94f-48ba-abf6-9c703ca7f569",
   "metadata": {},
   "source": [
    "# Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad99f91-44bd-43d0-b22d-64039847729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.model.history\n",
    "\n",
    "if history and hasattr(history, 'history'):\n",
    "    plt.figure(figsize = (10, 5))\n",
    "    for key, values in history.history.items():\n",
    "        plt.plot(values, label=key)\n",
    "    plt.title('Learning Curves')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Metric')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4ce60d-d499-4ccb-a4fa-8b32ff1424b6",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1853c3b-6b86-481a-94d3-31125b3583d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.evaluate(val_data)\n",
    "\n",
    "print(\\\"\\\\nEvaluation Metrics:\\\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\\\"{k}: {v:.4f}\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f792b1-4c03-41c6-8645-21d5e315c7f5",
   "metadata": {},
   "source": [
    "# Export The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58b7300-7ca9-4035-bbbe-8a88ab3fb79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(\n",
    "    export_dir='.',\n",
    "    export_format=[ExportFormat.TFLITE],\n",
    "    quantization_config=object_detector.QuantizationConfig.for_float16()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
